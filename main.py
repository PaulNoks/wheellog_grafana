import os
import pandas as pd
import logging
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "wheellog")
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASSWORD = os.getenv("DB_PASSWORD", "password")
UPLOAD_DIR = os.getenv("UPLOAD_DIR", "./uploads")

app = FastAPI()

os.makedirs(UPLOAD_DIR, exist_ok=True)

def get_db_connection():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = psycopg2.connect(
            host=DB_HOST, port=DB_PORT, database=DB_NAME,
            user=DB_USER, password=DB_PASSWORD
        )
        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å–ø–µ—à–Ω–æ")
        return conn
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        raise

def create_hypertable():
    """–°–æ–∑–¥–∞–Ω–∏–µ hypertable –¥–ª—è TimescaleDB"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # –°–æ–∑–¥–∞–µ–º –æ–±—ã—á–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS wheellog_data (
                timestamp TIMESTAMPTZ NOT NULL,
                file_name TEXT,
                latitude DOUBLE PRECISION DEFAULT 0,
                longitude DOUBLE PRECISION DEFAULT 0,
                gps_speed DOUBLE PRECISION DEFAULT 0,
                gps_alt DOUBLE PRECISION DEFAULT 0,
                gps_heading DOUBLE PRECISION DEFAULT 0,
                gps_distance DOUBLE PRECISION DEFAULT 0,
                speed DOUBLE PRECISION DEFAULT 0,
                voltage DOUBLE PRECISION DEFAULT 0,
                phase_current DOUBLE PRECISION DEFAULT 0,
                current DOUBLE PRECISION DEFAULT 0,
                power DOUBLE PRECISION DEFAULT 0,
                torque DOUBLE PRECISION DEFAULT 0,
                pwm DOUBLE PRECISION DEFAULT 0,
                battery_level DOUBLE PRECISION DEFAULT 0,
                distance DOUBLE PRECISION DEFAULT 0,
                totaldistance DOUBLE PRECISION DEFAULT 0,
                system_temp DOUBLE PRECISION DEFAULT 0,
                temp2 DOUBLE PRECISION DEFAULT 0,
                tilt DOUBLE PRECISION DEFAULT 0,
                roll DOUBLE PRECISION DEFAULT 0,
                mode TEXT,
                alert TEXT
            );
        """)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —É–∂–µ hypertable
        cursor.execute("""
            SELECT EXISTS (
                SELECT 1 FROM _timescaledb_catalog.hypertable
                WHERE table_name = 'wheellog_data'
            );
        """)

        is_hypertable = cursor.fetchone()[0]

        if not is_hypertable:
            logger.info("–°–æ–∑–¥–∞–µ–º hypertable...")
            cursor.execute("SELECT create_hypertable('wheellog_data', 'timestamp');")

            cursor.execute("""
                ALTER TABLE wheellog_data SET (
                    timescaledb.compress,
                    timescaledb.compress_segmentby = 'file_name'
                );
            """)

            cursor.execute("""
                SELECT add_compression_policy('wheellog_data', INTERVAL '7 days');
            """)

            logger.info("‚úÖ Hypertable —Å–æ–∑–¥–∞–Ω–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞!")
        else:
            logger.info("‚úÖ Hypertable —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ hypertable: {e}")
        if 'conn' in locals():
            conn.rollback()
            cursor.close()
            conn.close()
        raise

def _parse_timestamp(date_str: str, time_str: str) -> datetime:
    """–ü–∞—Ä—Å–∏–Ω–≥ timestamp –∏–∑ wheellog —Ñ–æ—Ä–º–∞—Ç–∞"""
    try:
        dt = datetime.strptime(f"{date_str} {time_str}", "%Y-%m-%d %H:%M:%S.%f")
        return dt.replace(tzinfo=datetime.now().astimezone().tzinfo)
    except ValueError:
        dt = datetime.strptime(f"{date_str} {time_str}", "%Y-%m-%d %H:%M:%S")
        return dt.replace(tzinfo=datetime.now().astimezone().tzinfo)

def _ingest_to_timescale(file_path: str, filename: str):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ TimescaleDB —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    logger.info(f"üì• –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞: {filename}")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists(file_path):
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return
            
        # –ß–∏—Ç–∞–µ–º CSV
        logger.info(f"üìñ –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª: {file_path}")
        df = pd.read_csv(file_path)
        logger.info(f"üìä –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏–∑ {filename}")
        
        # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"üîç –ö–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ: {list(df.columns)}")
        logger.info(f"üîç –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:\n{df.head(3)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = ['date', 'time']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
            return

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        numeric_columns = ["latitude","longitude","gps_speed","gps_alt","gps_heading","gps_distance",
                          "speed","voltage","phase_current","current","power","torque","pwm",
                          "battery_level","distance","totaldistance","system_temp","temp2","tilt","roll"]

        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        logger.info("üîå –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        conn = get_db_connection()
        cursor = conn.cursor()

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        insert_data = []
        errors_count = 0

        logger.info("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏...")
        for i, row in df.iterrows():
            try:
                ts = _parse_timestamp(str(row["date"]), str(row["time"]))
                insert_data.append((
                    ts, filename,
                    float(row.get("latitude", 0)), float(row.get("longitude", 0)),
                    float(row.get("gps_speed", 0)), float(row.get("gps_alt", 0)),
                    float(row.get("gps_heading", 0)), float(row.get("gps_distance", 0)),
                    float(row.get("speed", 0)), float(row.get("voltage", 0)),
                    float(row.get("phase_current", 0)), float(row.get("current", 0)),
                    float(row.get("power", 0)), float(row.get("torque", 0)),
                    float(row.get("pwm", 0)), float(row.get("battery_level", 0)),
                    float(row.get("distance", 0)), float(row.get("totaldistance", 0)),
                    float(row.get("system_temp", 0)), float(row.get("temp2", 0)),
                    float(row.get("tilt", 0)), float(row.get("roll", 0)),
                    str(row.get("mode", "")), str(row.get("alert", ""))
                ))
            except Exception as e:
                errors_count += 1
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {i}: {e}")
                if errors_count <= 3:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –æ—à–∏–±–∫–∏
                    logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω–∞—è —Å—Ç—Ä–æ–∫–∞: {row}")
                continue

        # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        if insert_data:
            logger.info(f"üíæ –í—Å—Ç–∞–≤–ª—è–µ–º {len(insert_data)} –∑–∞–ø–∏—Å–µ–π –≤ –ë–î...")
            insert_query = """

                    INSERT INTO wheellog_data (
                    timestamp, file_name, latitude, longitude, gps_speed, gps_alt,
                    gps_heading, gps_distance, speed, voltage, phase_current, current,
                    power, torque, pwm, battery_level, distance, totaldistance,
                    system_temp, temp2, tilt, roll, mode, alert
                ) VALUES %s
            """

            execute_values(cursor, insert_query, insert_data,
                          template=None, page_size=5000)

            conn.commit()
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(insert_data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {filename}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤—Å—Ç–∞–≤–∏–ª–∏—Å—å
            cursor.execute("SELECT COUNT(*) FROM wheellog_data WHERE file_name = %s", (filename,))
            count_in_db = cursor.fetchone()[0]
            logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞: –≤ –ë–î –Ω–∞–π–¥–µ–Ω–æ {count_in_db} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ñ–∞–π–ª–∞ {filename}")
            
        else:
            logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏!")

        if errors_count > 0:
            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {errors_count} —Å—Ç—Ä–æ–∫ —Å –æ—à–∏–±–∫–∞–º–∏")

        cursor.close()
        conn.close()
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {filename} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    except Exception as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filename}: {e}")
        logger.exception("–ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:")

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ TimescaleDB API...")
    try:
        create_hypertable()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

@app.post("/upload")
async def upload_csv(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞"""
    logger.info(f"üì§ –ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {file.filename}")
    
    if not file.filename.endswith(".csv"):
        raise HTTPException(status_code=400, detail="Only .csv files are accepted.")

    content = await file.read()
    if len(content) == 0:
        raise HTTPException(status_code=400, detail="Empty file.")

    dst_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(dst_path, "wb") as f:
        f.write(content)
    
    logger.info(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {dst_path}")
    logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(content)} bytes")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
    background_tasks.add_task(_ingest_to_timescale, dst_path, file.filename)
    logger.info(f"üîÑ –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –¥–ª—è —Ñ–∞–π–ª–∞: {file.filename}")
    
    return JSONResponse({
        "status": "ok", 
        "file": file.filename, 
        "message": "File uploaded and processing started",
        "file_size": len(content),
        "file_path": dst_path
    })

# –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
@app.post("/upload-sync")
async def upload_csv_sync(file: UploadFile = File(...)):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
    logger.info(f"üì§ –°–ò–ù–•–†–û–ù–ù–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file.filename}")
    
    if not file.filename.endswith(".csv"):
        raise HTTPException(status_code=400, detail="Only .csv files are accepted.")

    content = await file.read()
    if len(content) == 0:
        raise HTTPException(status_code=400, detail="Empty file.")

    dst_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(dst_path, "wb") as f:
        f.write(content)
    
    logger.info(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {dst_path}")
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        _ingest_to_timescale(dst_path, file.filename)
        return JSONResponse({
            "status": "ok", 
            "file": file.filename, 
            "message": "File uploaded and processed successfully"
        })
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
        raise HTTPException(status_code=500, detail=f"Processing failed: {str(e)}")

@app.get("/stats")
async def get_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º TimescaleDB —Ñ—É–Ω–∫—Ü–∏–π"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        cursor.execute("SELECT COUNT(*) FROM wheellog_data")
        total_records = cursor.fetchone()[0]

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª–∞–º
        cursor.execute("SELECT file_name, COUNT(*) FROM wheellog_data GROUP BY file_name ORDER BY COUNT(*) DESC")
        files_stats = cursor.fetchall()

        # –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
        cursor.execute("SELECT MIN(timestamp), MAX(timestamp) FROM wheellog_data")
        time_range = cursor.fetchone()

        # TimescaleDB chunks –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        cursor.execute("""
            SELECT
                chunk_name,
                range_start,
                range_end,
                is_compressed
            FROM timescaledb_information.chunks
            WHERE hypertable_name = 'wheellog_data'
            ORDER BY range_start DESC
            LIMIT 10
        """)
        chunks_info = cursor.fetchall()

        result = {
            "total_records": total_records,
            "files_count": len(files_stats),
            "files": dict(files_stats[:10]),
            "time_range": {
                "from": time_range[0],
                "to": time_range[1]
            },
            "chunks_count": len(chunks_info),
            "recent_chunks": [
                {
                    "name": chunk[0],
                    "start": chunk[1],
                    "end": chunk[2],
                    "compressed": chunk[3]
                } for chunk in chunks_info
            ]
        }
        
        cursor.close()
        conn.close()
        return result

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ API –∏ –ë–î"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.close()
        conn.close()
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ health check: {e}")
        raise HTTPException(status_code=503, detail=f"Database connection failed: {str(e)}")

# –ó–∞–ø—É—Å–∫: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
